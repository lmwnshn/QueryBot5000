{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fa725de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import hashlib\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import sqlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aada6351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/extracted/simple/postgresql-2021-12-06_160118.csv',\n",
       " 'data/extracted/simple/postgresql-2021-12-06_160210.csv',\n",
       " 'data/extracted/simple/postgresql-2021-12-06_160202.csv',\n",
       " 'data/extracted/simple/postgresql-2021-12-06_160154.csv',\n",
       " 'data/extracted/simple/postgresql-2021-12-06_160132.csv',\n",
       " 'data/extracted/simple/postgresql-2021-12-06_160149.csv',\n",
       " 'data/extracted/simple/postgresql-2021-12-06_160207.csv',\n",
       " 'data/extracted/simple/postgresql-2021-12-06_160205.csv',\n",
       " 'data/extracted/simple/postgresql-2021-12-06_160121.csv',\n",
       " 'data/extracted/simple/postgresql-2021-12-06_160048.csv',\n",
       " 'data/extracted/simple/postgresql-2021-12-06_160138.csv',\n",
       " 'data/extracted/simple/postgresql-2021-12-06_160127.csv',\n",
       " 'data/extracted/simple/postgresql-2021-12-06_160146.csv',\n",
       " 'data/extracted/simple/postgresql-2021-12-06_160135.csv',\n",
       " 'data/extracted/simple/postgresql-2021-12-06_160129.csv',\n",
       " 'data/extracted/simple/postgresql-2021-12-06_160124.csv',\n",
       " 'data/extracted/simple/postgresql-2021-12-06_160151.csv',\n",
       " 'data/extracted/simple/postgresql-2021-12-06_160157.csv',\n",
       " 'data/extracted/simple/postgresql-2021-12-06_160159.csv',\n",
       " 'data/extracted/simple/postgresql-2021-12-06_160140.csv',\n",
       " 'data/extracted/simple/postgresql-2021-12-06_160143.csv',\n",
       " 'data/extracted/simple/postgresql-2021-12-06_160114.csv']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pgfiles = glob.glob('data/extracted/simple/postgresql*.csv')\n",
    "display(pgfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9037dbb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(603434, 4)\n",
      "Index(['log_time', 'command_tag', 'session_start_time', 'message'], dtype='object')\n",
      "{nan, 'SELECT', 'DELETE', 'SHOW', 'SET', 'INSERT', 'BEGIN', 'COMMIT', 'ROLLBACK', 'UPDATE'}\n"
     ]
    }
   ],
   "source": [
    "# https://www.postgresql.org/docs/13/runtime-config-logging.html#RUNTIME-CONFIG-LOGGING-CSVLOG\n",
    "PG_LOG_COLUMNS = [\n",
    "    'log_time',\n",
    "    'user_name',\n",
    "    'database_name',\n",
    "    'process_id',\n",
    "    'connection_from',\n",
    "    'session_id',\n",
    "    'session_line_num',\n",
    "    'command_tag',\n",
    "    'session_start_time',\n",
    "    'virtual_transaction_id',\n",
    "    'transaction_id',\n",
    "    'error_severity',\n",
    "    'sql_state_code',\n",
    "    'message',\n",
    "    'detail',\n",
    "    'hint',\n",
    "    'internal_query',\n",
    "    'internal_query_pos',\n",
    "    'context',\n",
    "    'query',\n",
    "    'query_pos',\n",
    "    'location',\n",
    "    'application_name',\n",
    "    'backend_type',\n",
    "]\n",
    "\n",
    "\n",
    "df = pd.concat(\n",
    "    pd.read_csv(pgfile,\n",
    "                names=PG_LOG_COLUMNS,\n",
    "                parse_dates=['log_time', 'session_start_time'],\n",
    "                usecols=['log_time', 'session_start_time', 'command_tag', 'message'],\n",
    "                header=None,\n",
    "                index_col=False)\n",
    "    for pgfile in pgfiles\n",
    ")\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "print(set(df['command_tag']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054e366a",
   "metadata": {},
   "source": [
    "## Extracting the relevant queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c9adcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        UPDATE stock   SET S_QUANTITY = 38 ,        S_...\n",
       "1        UPDATE stock   SET S_QUANTITY = 76 ,        S_...\n",
       "2        UPDATE stock   SET S_QUANTITY = 43 ,        S_...\n",
       "3        UPDATE stock   SET S_QUANTITY = 73 ,        S_...\n",
       "4        UPDATE stock   SET S_QUANTITY = 89 ,        S_...\n",
       "                               ...                        \n",
       "28203    INSERT INTO order_line (OL_O_ID, OL_D_ID, OL_W...\n",
       "28204    INSERT INTO order_line (OL_O_ID, OL_D_ID, OL_W...\n",
       "28205    UPDATE stock   SET S_QUANTITY = 89 ,        S_...\n",
       "28206    UPDATE stock   SET S_QUANTITY = 43 ,        S_...\n",
       "28207    UPDATE stock   SET S_QUANTITY = 47 ,        S_...\n",
       "Name: query, Length: 603434, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commands = ['SELECT', 'INSERT', 'UPDATE', 'DELETE']\n",
    "\n",
    "def extract_query(message):\n",
    "    for command in commands:\n",
    "        idx = message.find(command)\n",
    "        if idx != -1:\n",
    "            query = message[idx:]\n",
    "            return query\n",
    "    return ''\n",
    "\n",
    "df['query'] = df['message'].apply(extract_query)\n",
    "df['query']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa46e16",
   "metadata": {},
   "source": [
    "## Anonymizer: salt and hash non-date non-digit strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaae2070",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANONYMIZE = False\n",
    "\n",
    "SALT = 'andycannotsay.com'.encode('utf-8')\n",
    "DATE_REGEX = re.compile(r'\\d{4}-\\d{2}-\\d{2}.*')\n",
    "DIGITS_REGEX = re.compile(r'\\d+\\.?\\d*')\n",
    "\n",
    "def anonymize(sql):\n",
    "    cleaned_tokens = []\n",
    "\n",
    "    # TODO(WAN): sqlparse.parse is actually quite slow.\n",
    "    # Do we really need this?\n",
    "    parsed = sqlparse.parse(sql)\n",
    "    if len(parsed) == 0:\n",
    "        return ''\n",
    "    \n",
    "    assert len(parsed) == 1\n",
    "    tokens = parsed[0].flatten()\n",
    "    for token in tokens:\n",
    "        token = str(token)\n",
    "\n",
    "        single_quoted = token.startswith(\"'\") and token.endswith(\"'\")\n",
    "        double_quoted = token.startswith('\"') and token.endswith('\"')\n",
    "        not_quoted = not single_quoted and not double_quoted\n",
    "\n",
    "        is_date = DATE_REGEX.search(token) is not None\n",
    "        is_digits = DIGITS_REGEX.search(token) is not None\n",
    "\n",
    "        if not_quoted or is_date or is_digits:\n",
    "            cleaned_tokens.append(token)\n",
    "            continue\n",
    "\n",
    "        sha = hashlib.sha256(SALT + token.encode('utf-8')).hexdigest()\n",
    "        clean_token = \"'{}\\\\{}'\".format(len(token) - 2, sha)\n",
    "        cleaned_tokens.append(clean_token)\n",
    "\n",
    "    return ''.join(cleaned_tokens)\n",
    "\n",
    "if ANONYMIZE:\n",
    "    df['query_anon'] = df['query'].apply(anonymize)\n",
    "    df['query_anon']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477f3c71",
   "metadata": {},
   "source": [
    "## Pre-processor: extracting query templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82d93be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        UPDATE stock   SET S_QUANTITY = # ,        S_Y...\n",
       "1        UPDATE stock   SET S_QUANTITY = # ,        S_Y...\n",
       "2        UPDATE stock   SET S_QUANTITY = # ,        S_Y...\n",
       "3        UPDATE stock   SET S_QUANTITY = # ,        S_Y...\n",
       "4        UPDATE stock   SET S_QUANTITY = # ,        S_Y...\n",
       "                               ...                        \n",
       "28203    INSERT INTO order_line (OL_O_ID, OL_D_ID, OL_W...\n",
       "28204    INSERT INTO order_line (OL_O_ID, OL_D_ID, OL_W...\n",
       "28205    UPDATE stock   SET S_QUANTITY = # ,        S_Y...\n",
       "28206    UPDATE stock   SET S_QUANTITY = # ,        S_Y...\n",
       "28207    UPDATE stock   SET S_QUANTITY = # ,        S_Y...\n",
       "Name: query_template, Length: 603434, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STRING_REGEX = r'([^\\\\])\\'((\\')|(.*?([^\\\\])\\'))'\n",
    "DOUBLE_QUOTE_STRING_REGEX = r'([^\\\\])\"((\")|(.*?([^\\\\])\"))'\n",
    "INT_REGEX = r'([^a-zA-Z])-?\\d+(\\.\\d+)?'\n",
    "HASH_REGEX = r'(\\'\\d+\\\\.*?\\')'\n",
    "\n",
    "def extract_template(query):\n",
    "    template = query\n",
    "    template = re.sub(HASH_REGEX, r\"@@@\", template)\n",
    "    template = re.sub(STRING_REGEX, r\"\\1&&&\", template)\n",
    "    template = re.sub(DOUBLE_QUOTE_STRING_REGEX, r\"\\1&&&\", template)\n",
    "    template = re.sub(INT_REGEX, r\"\\1#\", template)\n",
    "    return template\n",
    "\n",
    "query_column = 'query_anon' if ANONYMIZE else 'query'\n",
    "\n",
    "df['query_template'] = df[query_column].apply(extract_template)\n",
    "df['query_template']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cb57547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2021-12-06 16:01:18-05:00\n",
       "1       2021-12-06 16:01:18-05:00\n",
       "2       2021-12-06 16:01:18-05:00\n",
       "3       2021-12-06 16:01:18-05:00\n",
       "4       2021-12-06 16:01:18-05:00\n",
       "                   ...           \n",
       "28203   2021-12-06 16:01:18-05:00\n",
       "28204   2021-12-06 16:01:18-05:00\n",
       "28205   2021-12-06 16:01:18-05:00\n",
       "28206   2021-12-06 16:01:18-05:00\n",
       "28207   2021-12-06 16:01:18-05:00\n",
       "Name: log_time_s, Length: 603434, dtype: datetime64[ns, pytz.FixedOffset(-300)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['log_time_s'] = df['log_time'].round('S')\n",
    "df['log_time_s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ba90ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query_template</th>\n",
       "      <th>log_time_s</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">DELETE FROM new_order WHERE NO_O_ID = #    AND NO_D_ID = #   AND NO_W_ID = #</th>\n",
       "      <th>2021-12-06 16:01:12-05:00</th>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-06 16:01:13-05:00</th>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-06 16:01:14-05:00</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-06 16:01:15-05:00</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-06 16:01:16-05:00</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">UPDATE warehouse   SET W_YTD = W_YTD + #  WHERE W_ID = #</th>\n",
       "      <th>2021-12-06 16:02:08-05:00</th>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-06 16:02:09-05:00</th>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-06 16:02:10-05:00</th>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-06 16:02:11-05:00</th>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-06 16:02:12-05:00</th>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1929 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              count\n",
       "query_template                                     log_time_s                      \n",
       "DELETE FROM new_order WHERE NO_O_ID = #    AND ... 2021-12-06 16:01:12-05:00    110\n",
       "                                                   2021-12-06 16:01:13-05:00    158\n",
       "                                                   2021-12-06 16:01:14-05:00     75\n",
       "                                                   2021-12-06 16:01:15-05:00    137\n",
       "                                                   2021-12-06 16:01:16-05:00     90\n",
       "...                                                                             ...\n",
       "UPDATE warehouse   SET W_YTD = W_YTD + #  WHERE... 2021-12-06 16:02:08-05:00    159\n",
       "                                                   2021-12-06 16:02:09-05:00    174\n",
       "                                                   2021-12-06 16:02:10-05:00    161\n",
       "                                                   2021-12-06 16:02:11-05:00    169\n",
       "                                                   2021-12-06 16:02:12-05:00    126\n",
       "\n",
       "[1929 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = df.groupby(['query_template', 'log_time_s']).size()\n",
    "grouped_df = pd.DataFrame(gb, columns=['count'])\n",
    "grouped_df.drop('', axis=0, level=0, inplace=True)\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa6f4bc",
   "metadata": {},
   "source": [
    "## Clusterer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5832cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(WAN): Port online_clustering.py.\n",
    "# TODO(WAN): I would be somewhat surprised if sklearn doesn't have this built in... We'll see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25a4d975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_date = grouped_df.index.get_level_values(1).min()\n",
    "max_date = grouped_df.index.get_level_values(1).max()\n",
    "\n",
    "rho = 0.8\n",
    "cluster_gap = 1440\n",
    "n = (max_date - min_date).seconds // 60 + (max_date - min_date).days * 1440 + 1\n",
    "num_gaps = n // cluster_gap\n",
    "\n",
    "centers, cluster_totals, cluster_sizes = {}, {}, {}\n",
    "\n",
    "assignments = [(min_date, {template: -1 for template in grouped_df.index.get_level_values(0)})]\n",
    "\n",
    "current_date = min_date\n",
    "next_cluster = 0\n",
    "\n",
    "n_sample = 10000\n",
    "\n",
    "\n",
    "\n",
    "# AdjustCluster(month_min_date, current_date, next_date, data, assignments[-1][1],\n",
    "#                next_cluster, centers, cluster_totals, total_queries, cluster_sizes, rho)\n",
    "\n",
    "# def AdjustCluster(min_date, current_date, next_date, data, last_ass,\n",
    "#        next_cluster, centers, cluster_totals, total_queries, cluster_sizes, rho):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dd71d8",
   "metadata": {},
   "source": [
    "## Forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee20bda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(WAN): Port exp_multi_online_continuous.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
